# 概述

## 为什么要优化

- 系统的吞吐量瓶颈往往出现在数据库的访问速度上
- 随着应用程序的运行，数据库的中的数据会越来越多，处理时间会相应变慢
- 数据是存放在磁盘上的，读写速度无法和内存相比

## 如何优化

- 设计数据库时：数据库表、字段的设计，存储引擎
- 利用好MySQL自身提供的功能，如索引等
- 横向扩展：MySQL集群、负载均衡、读写分离
- SQL语句的优化

### 字段设计

字段类型的选择，设计规范，范式，常见设计案例

#### 原则：定长和非定长数据类型的选择

#### 优先使用定长的数据类型

decimal不会损失精度，存储空间会随数据的增大而增大。double占用固定空间，较大数的存储会损失精度。非定长的还有varchar、text

**金额**

- 对数据的精度要求较高

     用decimal(8,2)有2位小数的定点数，定点数支持很大的数（甚至是超过int,bigint存储范围的数）

- 对数据的精度要求较一般的话

    可用float，单位为分

- 对数据的精度无要求的话

    用字符串

**字符串存储**

定长char，非定长varchar、text（上限65535，其中varchar还会消耗1-3字节记录长度，而text使用额外空间记录长度）

#### 原则：尽可能选择小的数据类型和指定短的长度

#### 原则：尽可能使用 not null

非null字段的处理要比null字段的处理高效些！且不需要判断是否为null。

null在MySQL中，不好处理，存储需要额外空间，运算也需要特殊的运算符。如select null = null和select null <> null（<>为不等号）有着同样的结果，只能通过is null和is not null来判断字段是否为null。

如何存储？MySQL中每条记录都需要额外的存储空间，表示每个字段是否为null。因此通常使用特殊的数据进行占位，比如int not null default 0、string not null default ‘’

#### 原则：字段注释要完整，见名知意

#### 原则：单表字段不宜过多

二三十个就极限了

#### 原则：可以预留字段

在使用以上原则之前首先要满足业务需求

### 关联表的设计

不建议使用外键，最好软关联，用代码处理其关联关系

### 范式 

数据表的设计规范，一套越来越严格的规范体系（如果需要满足N范式，首先要满足N-1范式）。

#### 第一范式1NF：字段原子性

字段原子性，字段不可再分割。

关系型数据库，默认满足第一范式

注意比较容易出错的一点，在一对多的设计中使用逗号分隔多个外键，这种方法虽然存储方便，但不利于维护和索引（比如查找带标签java的文章）。

但也不反对使用 json 适当冗余一些数据，最好还是基于业务设计。

如果选择冗余了，一定要维护好该字段。

mysql 5.7 版本后已经支持json 类型字段。

#### 第二范式：属性完全依赖于主键 

即在表中加上一个与业务逻辑无关的字段作为主键

主键：可以唯一标识记录的字段或者字段集合。

简单的说，就是一张表，里面的字段就是一个事物的所有属性 + Id

比如说：桌子。有名称，材质 等多个与桌子相关的字段，这些字段 + id 的集合 就是一个表。

#### 第三范式：消除对主键的传递依赖

一个数据库表中不包含已在其它表中已包含的非主关键字信息。

A表 有 （Id， A1，A2，A3） 字段

 B表 有 （Id， B1，B2，A1，A2，A3） 字段

A表 有 （Id， A1，A2，A3） 字段

 B表 有 （Id， B1，B2，AID） 字段



这个三范式啊，也就是知道知道，具体情况具体分析。适当冗余没啥毛病。

反范式也一样能玩。

尽量遵守范式。如果说当前业务，违反一些范式的要求，也可以做，具体情况具体分析。

### 存储引擎选择

早期问题：如何选择MyISAM和Innodb？

现在不存在这个问题了，Innodb不断完善，从各个方面赶超MyISAM，也是MySQL默认使用的。

如果没有特别的需求，使用默认的Innodb即可。

MyISAM：以读写插入为主的应用程序，比如博客系统、新闻门户网站。

Innodb：更新（删除）操作频率也高，或者要保证数据的完整性；并发量高，支持事务和外键保证数据完整性。比如OA自动化办公系统。

### 索引

关键字与数据的映射关系称为索引（==包含关键字和对应的记录在磁盘中的地址==）。关键字是从数据当中提取的用于标识、检索数据的特定内容。

#### 索引检索为什么快？

- 关键字相对于数据本身，**数据量小**
- 关键字是 **有序** 的，二分查找可快速确定位置

图书馆为每本书都加了索引号（类别-楼层-书架）、字典为词语解释按字母顺序编写目录等都用到了索引。

#### MySQL中索引类型

**普通索引**（key），**唯一索引**（unique key），**主键索引**（primary key），**全文索引**（fulltext key）

三种索引的索引方式是一样的，只不过对索引的关键字有不同的限制：

- 普通索引：对关键字没有限制
- 唯一索引：要求记录提供的关键字不能重复
- 主键索引：要求关键字唯一且不为null
  

#### **执行计划explain**

MySQL 提供了一个 EXPLAIN 命令，它可以对 `SELECT` 语句进行分析，并输出 `SELECT` 执行的详细信息，以供开发人员针对性优化.

```sql
EXPLAIN SELECT * from <tablename> WHERE id < 300;
```

#### **索引使用场景**

**where**  

**order by **

**join**

#### **索引覆盖**

如果要查询的字段都建立过索引，那么引擎会直接在索引表中查询而不会访问原始数据（否则只要有一个字段没有建立索引就会做全表扫描），这叫索引覆盖。因此我们需要尽可能的在select后 **只写必要的查询字段**，以增加索引覆盖的几率。

这里值得注意的是不要想着为每个字段建立索引，因为优先使用索引的优势就在于其体积小。

#### 语法细节（要点）

在满足索引使用的场景下（**where/order by/join on或索引覆盖**），索引也不一定被使用

##### 字段要独立出现,避免函数和运算符

比如下面两条SQL语句在语义上相同，但是第一条会使用主键索引而第二条不会。

```sql
 explain select  * FROM `innodb1` where id  = 1 ;
 explain select  * FROM `innodb1` where id +1  = 2;
```

##### like查询，不能以通配符开头(最左匹配)

比如搜索标题包含mysql的文章：

```sql
 select  * FROM `innodb1` where information LIKE  '%山派'
```

这种SQL的执行计划用不了索引（like 语句匹配表达式以通配符开头），因此只能做全表扫描，效率极低，在实际工程中几乎不被采用。而一般会使用第三方提供的支持中文的全文索引来做,如 elasticsearch 。

但是 **关键字查询** 热搜提醒功能还是可以做的，。用到的语句是：

```sql
 select  * FROM `innodb1` where information LIKE  '华%'
```

这种like是可以利用索引的（当然前提是information字段建立过索引）。

##### 复合索引只对第一个字段有效

建立复合索引：

```sql
alter table innodb1 add index(first_name,last_name); 
```

其原理就是将索引先按照从first_name中提取的关键字排序，如果无法确定先后再按照从last_name提取的关键字排序，也就是说该索引表只是按照记录的first_name字段值有序。

```sql
--可以利用索引的 first_name
select * from innodb1 where first_name = ?
--无法利用索引 last_name
select * from innodb1 where last_name = ? 
```



##### 复合索引的应用场景是什么？

###### 组合查询

比如对于`select * innodb1  from first_name = ? and last_name = ?`，复合索引就比对first_name和last_name单独建立索引要高效些。很好理解，复合索引首先二分查找与first_name = ?匹配的记录，再在这些记录中二分查找与last_name匹配的记录，只涉及到一张索引表。而分别单独建立索引则是在first_name索引表中二分找出与first_name = ?匹配的记录，再在last_name索引表中二分找出与last_name = ?的记录，两者取交集。

###### "or"，两边条件都有索引可用

**有一边无索引可用**就会导致整个SQL语句的全表扫描

###### 状态值，不容易使用到索引

如性别、支付状态等状态值字段往往只有极少的几种取值可能，这种字段即使建立索引，也往往利用不上。这是因为，一个状态值可能匹配大量的记录，这种情况MySQL会认为利用索引比全表扫描的效率低，从而弃用索引。索引是随机访问磁盘，而全表扫描是顺序访问磁盘，这就好比有一栋20层楼的写字楼，楼底下的索引牌上写着某个公司对应不相邻的几层楼，你去公司找人，与其按照索引牌的提示去其中一层楼没找到再下来看索引牌再上楼，不如从1楼挨个往上找到顶楼。

##### 复合索引创建

假设有一个 3 列复合索引 (col1,col2,col3), 那么 MySQL 只会会建立三个索引 (col1),(col1,col2),(col1,col2,col3)。

##### 复合索引的执行

当我们创建一个三列复合索引(col1,col2,col3)时,SQL语句中的where条件可以为where col2 = x and col1 = x

虽然这个语句不符合最左前缀匹配,但是因为col2 在前 和 col1 在前的查询结果都是一致的,所以mysql 查询优化器会自动纠正使得sql语句能够以最高的查询效率执行.

#### 如何创建索引

- 建立基础索引：在**where、order by、join**字段上建立索引。
- 优化，组合索引：基于业务逻辑
- 如果条件经常性出现在一起，那么可以考虑将多字段索引升级为  **复合索引** 
- 如果通过增加个别字段的索引，就可以出现 **索引覆盖**，那么可以考虑为该字段建立索引
- 查询时，不常用到的索引，应该删除掉

#### 前缀索引

语法：index(field(10))，使用字段值的前10个字符建立索引，默认是使用字段的全部内容建立索引。

前提：前缀的标识度高。比如密码就适合建立前缀索引，因为密码几乎各不相同。

```sql
ALTER TABLE table_name ADD KEY(column_name(2));
```

实操的难度：**在于前缀截取的长度**。



#### 索引的存储结构

##### BTree

btree（多路平衡查找树）是一种广泛应用于 **磁盘上实现索引功能**的一种数据结构，也是大多数数据库索引表的实现。

BTree的一个node可以存储多个关键字，node的大小取决于计算机的文件系统，因此我们可以通过减小索引字段的长度使结点存储更多的关键字。如果node中的关键字已满，那么可以通过每个关键字之间的子节点指针来拓展索引表，但是不能破坏结构的有序性，比如按照first_name第一有序、last_name第二有序的规则，新添加的韩香就可以插到韩康之后。白起 < 韩飞 < 李世民  。这与二叉搜索树的思想是一样的，只不过二叉搜索树的查找效率是log(2,N)（以2为底N的对数），而BTree的查找效率是log(x,N)（其中x为node的关键字数量，可以达到1000以上）。

从log(1000+,N)可以看出，少量的磁盘读取即可做到大量数据的遍历，这也是btree的设计目的。

##### B+Tree聚簇结构

聚簇结构（也是在BTree上升级改造的）中，关键字和记录是存放在一起的。

在MySQL中，仅仅只有Innodb的**主键索引为聚簇结构**，其它的索引包括Innodb的非主键索引都是典型的BTree结构。

##### 哈希索引

在索引被载入内存时，使用哈希结构来存储。

#### sql查询缓存相关

不要用，如果要缓存，那么就在代码内使用缓存。



### 分库分表

#### hash

最常见的分区方案是按id分表 

#### range算法

是一种**条件分表**算法，按照数据大小范围分区（将数据使用某种条件，分散到不同的表中）。

如创建时间 或其他字段，

#### 水平分割和垂直分割

水平分割：通过建立结构相同的几张表分别存储数据

垂直分割：将经常一起使用的字段放在一个单独的表中，分割后的表记录之间是一一对应关系。

#### 分表原因

- 为数据库减压
- 分区算法局限
- 数据库支持不完善（5.1之后mysql才支持分区操作）

##### id重复的解决方案

- 借用第三方应用如memcache、redis的id自增器
- 单独建一张只包含id一个字段的表，每次自增该字段作为数据记录的id
- UUid 、twitter snow flake

#### 集群

横向扩展：从根本上（单机的硬件处理能力有限）提升数据库性能 。由此而生的相关技术：**读写分离**、**负载均衡**

##### 主从复制：

- 数据安全 - 从库可以随时停下来备份数据，而不必考虑服务不可用的问题。

- 数据分析 - 在从库上分析数据，不会影响主库的性能

- 远程数据分配 - 可以通过从库创建数据提供给远端的网站使用，而不必暴露主库

##### 读写分离

读写分离是依赖于主从复制，而主从复制又是为读写分离服务的。

因为主从复制要求slave不能写只能读（如果对slave执行写操作，那么show slave status将会呈现Slave_SQL_Running=NO，此时你需要按照前面提到的手动同步一下slave）。

水平扩展，读写分离 - 在这种架构下，所有的增/删/改操作在Master上执行，所有的读操作在Slaves上执行，这样可以把并行压力分担到多个从库

**方案一、定义两种连接**

就像我们在学JDBC时定义的DataBase一样，我们可以抽取出ReadDataBase,WriteDataBase implements DataBase，但是这种方式无法利用优秀的线程池技术如DruidDataSource帮我们管理连接，也无法利用Spring AOP让连接对DAO层透明。

**方案二、使用Spring AOP**

如果能够使用Spring AOP解决数据源切换的问题，那么就可以和Mybatis、Druid整合到一起了。

我们在整合Spring和Mybatis时，我们只需写DAO接口和对应的SQL语句，那么DAO实例是由谁创建的呢？实际上就是Spring帮我们创建的，它通过我们注入的数据源，帮我们完成从中获取数据库连接、使用连接执行 SQL 语句的过程以及最后归还连接给数据源的过程。

如果我们能在调用DAO接口时根据接口方法命名规范（增addXXX/createXXX、删deleteXX/removeXXX、改updateXXXX、查selectXX/findXXX/getXX/queryXXX）动态地选择数据源（读数据源对应连接master而写数据源对应连接slave），那么就可以做到读写分离了。

##### 负载均衡

###### 负载均衡算法

- 轮询
- 加权轮询：按照处理能力来加权
- 负载分配：依据当前的空闲状态（但是测试每个节点的内存使用率、CPU利用率等，再做比较选出最闲的那个，效率太低）

###### 高可用

在服务器架构时，为了保证服务器7x24不宕机在线状态，需要为每台单点服务器（由一台服务器提供服务的服务器，如写服务器、数据库中间件）提供冗余机。

对于写服务器来说，需要提供一台同样的写-冗余服务器，当写服务器健康时（写-冗余通过心跳检测），写-冗余作为一个从机的角色复制写服务器的内容与其做一个同步；当写服务器宕机时，写-冗余服务器便顶上来作为写服务器继续提供服务。对外界来说这个处理过程是透明的，即外界仅通过一个IP访问服务。

### sql优化

#### limit offset,rows

尽量保证不要出现大的offset，比如limit 10000,10相当于对已查询出来的行数弃掉前10000行后再取10行，完全可以加一些条件过滤一下（完成筛选），而不应该使用limit跳过已查询到的数据。这是一个**offset做无用功**的问题。对应实际工程中，要避免出现大页码的情况，尽量引导用户做条件过滤。

#### select * 要少用

即尽量选择自己需要的字段select，但这个影响不是很大，因为网络传输多了几十上百字节也没多少延时，并且现在流行的ORM框架都是用的select  *，只是我们在**设计表的时候注意将大数据量的字段分离**，比如商品详情可以单独抽离出一张商品详情表，这样在查看商品简略页面时的加载速度就不会有影响了。

#### order by rand()不要用

它的逻辑就是随机排序（为每条数据生成一个随机数，然后根据随机数大小进行排序）。如select * from student order by rand() limit 5的执行效率就很低，因为它为表中的每条数据都生成随机数并进行排序，而我们只要前5条。

解决思路：在应用程序中，将随机的主键生成好，去数据库中利用主键检索。

#### 单表和多表查询

多表查询：join、子查询都是涉及到多表的查询。如果你使用explain分析执行计划你会发现多表查询也是一个表一个表的处理，最后合并结果。因此可以说单表查询将计算压力放在了应用程序上，而多表查询将计算压力放在了数据库上。

现在有ORM框架帮我们解决了单表查询带来的对象映射问题（查询单表时，如果发现有外键自动再去查询关联表，是一个表一个表查的）。

#### limit 1

如果可以确定仅仅检索一条，建议加上limit 1，其实ORM框架帮我们做到了这一点（查询单条的操作都会自动加上limit 1）。

#### 慢查询日志

用于记录执行时间超过某个临界值的SQL日志，用于快速定位慢查询，为我们的优化做参考。

##### 开启慢查询日志

配置项：slow_query_log

可以使用show variables like ‘slov_query_log’查看是否开启，如果状态值为OFF，可以使用set GLOBAL slow_query_log = on来开启，它会在datadir下产生一个xxx-slow.log的文件。

#### 设置临界时间

配置项：long_query_time

查看：show VARIABLES like 'long_query_time'，单位秒

设置：set long_query_time=0.5

实操时应该从长时间设置到短的时间，即将最慢的SQL优化掉

#### 查看日志

一旦SQL超过了我们设置的临界时间就会被记录到xxx-slow.log中

#### profile信息

配置项：profiling

**开启profile**

set profiling=on

开启后，所有的SQL执行的详细信息都会被自动记录下来



#### 通过Query_ID查看某条SQL所有详细步骤的时间

show profile for query Query_ID

上面show profiles的结果中，每个SQL有一个Query_ID，可以通过它查看执行该SQL经过了哪些步骤，各消耗了多场时间

  

