###  一条`SQL`查询语句是如何执行的

![page1](https://github.com/a827871781/Java-notes/blob/master/images/1.png)

### 一条SQL更新语句是如何执行的

1. 执行器先找引擎查询的数据。引擎直接用树搜索找到这一行。如果这一行所在的数据页本来就在内存中，就直接返回给执行器；否则，需要先从磁盘读入内存，然后再返回。
2. 执行器拿到引擎给的行数据，把这个值更新，得到新的一行数据，再调用引擎接口写入这行新数据。
3. 引擎将这行新数据更新到内存中，同时将这个更新操作记录到redo log里面，此时redo log处于prepare状态。然后告知执行器执行完成了，随时可以提交事务。
4. 执行器生成这个操作的`binlog`，并把`binlog`写入磁盘。
5. 执行器调用引擎的提交事务接口，引擎把刚刚写入的redo log改成提交（commit）状态，更新完成。

**两种日志区别**

酒店掌柜有一个粉板，专门用来记录客人的赊账记录。如果赊账的人不多，那么他可以把顾客名和账目写在板上。但如果赊账的人多了，粉板总会有记不下的时候，这个时候掌柜一定还有一个专门记录赊账的账本。

如果有人要赊账或者还账的话，掌柜一般有两种做法：

- `binlog`：一种做法是直接把账本翻出来，把这次赊的账加上去或者扣除掉；
- `redo log`：另一种做法是先在粉板上记下这次的账，等打烊以后再把账本翻出来核算。

1. `redo log`是`InnoDB`引擎特有的；`binlog`是`MySQL`的`Server`层实现的，所有引擎都可以使用。
2. `redo log`是物理日志，记录的是“在某个数据页上做了什么修改”；`binlog`是逻辑日志，记录的是这个语句的原始逻辑，比如`“给ID=2这一行的c字段加1 ”`。
3. `redo log`是循环写的，空间固定会用完；`binlog`是可以追加写入的。“追加写”是指`binlog`文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。`

`注：不建议在mysql内使用缓存，如果有需要做缓存，在应用层加入。并且mysql在8版本以后也去除掉了缓存`

### 讲事务隔离：事务隔离的实现

在`MySQL`中，实际上每条记录在更新的时候都会同时记录一条回滚操作。记录上的最新值，通过回滚操作，都可以得到前一个状态的值。

假设一个值从1被按顺序改成了2、3、4，在回滚日志里面就会有类似下面的记录。

![](https://github.com/a827871781/Java-notes/blob/master/images/2.png)

在查询这条记录的时候，不同时刻启动的事务会有不同的版本视图。如图中看到的，在版本A、B、C、D里面，这一个记录的值分别是1、2、3、4，同一条记录在系统中可以存在多个版本，就是数据库的多版本并发控制（`MVCC`）。对于版本 A，要得到1，就必须将当前值依次执行图中所有的回滚操作得到。

**基于上面的说明**
长事务意味着系统里面会存在很老的事务视图。由于这些事务随时可能访问数据库里面的任何数据，所以这个事务提交之前，数据库里面它可能用到的回滚记录都必须保留，这就会导致大量占用存储空间。除了对回滚段的影响，长事务还占用锁资源，也可能拖垮整个库，所以建议尽量不要使用长事务。

### 索引

什么是索引：为了提高数据查询的效率，概念类似书的目录。

#### 索引的常见模型

索引的出现是为了提高查询效率，但是实现索引的方式却有很多种，所以这里也就引入了索引模型的概念。可以用于提高读写效率的数据结构很多，分别是哈希表、有序数组和搜索树。

**哈希表**是一种以键-值（key-value）存储数据的结构,概念等同于`Hashmap`,哈希表这种结构适用于只有等值查询的场景

**有序数组**在等值查询和范围查询场景中的性能就非常优秀,查询和删除效率等同于List

**二叉搜索树**特点是：每个节点的左儿子小于父节点，父节点又小于右儿子。查询 更新都是O(log(N)

二叉树是搜索效率最高的但数据库存储不使用二叉树，因为索引不止在内存也在磁盘。

你可以想象一下一棵100万节点的平衡二叉树，树高20。一次查询可能需要访问20个数据块。在机械硬盘时代，从磁盘随机读一个数据块需要10 ms左右的寻址时间。也就是说，对于一个100万行的表，如果使用二叉树来存储，单独访问一个行可能需要20个10 ms的时间，这个查询可真够慢的。

为了让一个查询尽量少地读磁盘，就必须让查询过程访问尽量少的数据块。那么，我们就不应该使用二叉树，而是要使用“N叉”树。这里，“N叉”树中的“N”取决于数据块的大小。

以`InnoDB`的一个整数字段索引为例，这个N差不多是1200。这棵树高是4的时候，就可以存1200的3次方个值，这已经17亿了。考虑到树根的数据块总是在内存中的，一个10亿行的表上一个整数字段的索引，查找一个值最多只需要访问3次磁盘。其实，树的第二层也有很大概率在内存中，那么访问磁盘的平均次数就更少了

**N叉树（多路平衡查找树 、B树）**在读写上的性能优异，以及适配磁盘的访问模式，已经被广泛应用在数据库引擎中

#### B+树

- 从根节点到叶节点的所有路径都具有相同的长度
- 所有数据信息都存储在叶节点上，非叶节点仅作为叶节点的索引存在
- 根结点至少拥有两个键值对
- 每个树节点最多拥有M个键值对
- 每个树节点（除了根节点）拥有至少M/2个键值对



#### `InnoDB `的索引模型

在`InnoDB`中，表都是根据主键顺序以索引的形式存放的，这种存储方式的表称为索引组织表。`InnoDB`使用了**B+树索引模型**，所以数据都是存储在B+树中的。

把整颗树的高度维持在很小的范围内，同时在内存里缓存前面若干层的节点，可以极大地降低访问磁盘的次数，提高读的效率。

B+树的插入可能会引起数据页的分裂，删除可能会引起数据页的合并，二者都是比较重的IO消耗，所以比较好的方式是顺序插入数据，这也是我们一般使用自增主键的原因之一。

#### 索引类型：

主键索引、非主键索引

主键索引的叶子节点存的是整行的数据(聚簇索引)，非主键索引的叶子节点内容是主键的值(二级索引)

普通索引查询方式，则需要先搜索普通索引树，得到主键值，再到主键索引树搜索一次。这个过程称为回表。

基于非主键索引的查询需要多扫描一棵索引树。因此，我们在应用中应该尽量使用主键查询。

N叉树的N值在`MySQL`中是可以被人工调整的么？

5.6以后可以通过page大小来间接控制

#### 覆盖索引

如果执行的语句是select ID from T where k between 3 and 5，这时只需要查ID的值，而ID的值已经在k索引树上了，因此可以直接提供查询结果，不需要回表。也就是说，在这个查询里面，索引k已经“覆盖了”我们的查询需求，我们称为**覆盖索引**。

由于覆盖索引可以减少树的搜索次数，显著提升查询性能，所以使用覆盖索引是一个常用的性能优化手段。

#### 最左前缀原则

B+树这种索引结构，可以利用索引的“最左前缀”，来定位记录

1、覆盖索引：如果查询条件使用的是普通索引（或是联合索引的最左原则字段），查询结果是联合索引的字段或是主键，不用回表操作，直接返回结果，减少IO磁盘读写读取正行数据
2、最左前缀：联合索引的最左 N 个字段，也可以是字符串索引的最左 M 个字符
3、联合索引：根据创建联合索引的顺序，以最左原则进行where检索，比如（age，name）以age=1 或 age= 1 and name=‘张三’可以使用索引，单以name=‘张三’ 不会使用索引，考虑到存储空间的问题，还请根据业务需求，将查找频繁的数据进行靠左创建索引。
4、索引下推：like 'hello%’and age >10 检索，`MySQL5.6`版本之前，会对匹配的数据进行回表查询。5.6版本后，会先过滤掉age<10的数据，再进行回表查询，减少回表率，提升检索速度

### 数据库锁

  根据加锁范围：MySQL里面的锁可以分为：全局锁、表级锁、行级锁

**一、全局锁：**
对整个数据库实例加锁。
MySQL提供加全局读锁的方法：Flush tables with read lock(FTWRL)
这个命令可以使整个库处于只读状态。使用该命令之后，数据更新语句、数据定义语句和更新类事务的提交语句等操作都会被阻塞。
使用场景：全库逻辑备份。
风险：
1.如果在主库备份，在备份期间不能更新，业务停摆
2.如果在从库备份，备份期间不能执行主库同步的binlog，导致主从延迟
官方自带的逻辑备份工具mysqldump，当mysqldump使用参数--single-transaction的时候，会启动一个事务，确保拿到一致性视图。而由于MVCC的支持，这个过程中数据是可以正常更新的。
一致性读是好，但是前提是引擎要支持这个隔离级别。
如果要全库只读，为什么不使用set global readonly=true的方式？
1.在有些系统中，readonly的值会被用来做其他逻辑，比如判断主备库。所以修改global变量的方式影响太大。
2.在异常处理机制上有差异。如果执行FTWRL命令之后由于客户端发生异常断开，那么MySQL会自动释放这个全局锁，整个库回到可以正常更新的状态。而将整个库设置为readonly之后，如果客户端发生异常，则数据库就会一直保持readonly状态，这样会导致整个库长时间处于不可写状态，风险较高。
**二、表级锁**
MySQL里面表级锁有两种，一种是表锁，一种是元数据锁(meta data lock,MDL)
表锁的语法是:lock tables ... read/write
可以用unlock tables主动释放锁，也可以在客户端断开的时候自动释放。lock tables语法除了会限制别的线程的读写外，也限定了本线程接下来的操作对象。
对于InnoDB这种支持行锁的引擎，一般不使用lock tables命令来控制并发，毕竟锁住整个表的影响面还是太大。
MDL：不需要显式使用，在访问一个表的时候会被自动加上。
MDL的作用：保证读写的正确性。
在对一个表做增删改查操作的时候，加MDL读锁；当要对表做结构变更操作的时候，加MDL写锁。
读锁之间不互斥。读写锁之间，写锁之间是互斥的，用来保证变更表结构操作的安全性。
MDL 会直到事务提交才会释放，在做表结构变更的时候，一定要小心不要导致锁住线上查询和更新。  
**三、行级锁**
两阶段锁：在 InnoDB 事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放， 而是要等到事务结束时才释放。
建议：如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放。
死锁：当并发系统中不同线程出现循环资源依赖，涉及的线程都在等待别的线程释放资源时，就会导致这几个线程都进入无限等待的状态。
解决方案：
1、通过参数 innodb_lock_wait_timeout 根据实际业务场景来设置超时时间，InnoDB引擎默认值是50s。
2、发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数 innodb_deadlock_detect 设置为 on，表示开启这个逻辑（默认是开启状态）。
如何解决热点行更新导致的性能问题？
1、如果你能确保这个业务一定不会出现死锁，可以临时把死锁检测关闭掉。一般不建议采用
2、控制并发度，对应相同行的更新，在进入引擎之前排队。这样在InnoDB内部就不会有大量的死锁检测工作了。
3、将热更新的行数据拆分成逻辑上的多行来减少锁冲突，但是业务复杂度可能会大大提高。
innodb行级锁是通过锁索引记录实现的，如果更新的列没建索引是会锁住整个表的。   

### 事务是否隔离

RR:可重复读 

RC：读已提交

1. innodb支持RC和RR隔离级别实现是用的一致性视图(consistent read view)

2. 事务在启动时会拍一个快照,这个快照是基于整个库的.
   基于整个库的意思就是说一个事务内,整个库的修改对于该事务都是不可见的(对于快照读的情况)
   如果在事务内select t表,另外的事务执行了DDL t表,根据发生时间,要么锁住要么报错

3. 事务是如何实现的MVCC呢?
   (1)每个事务都有一个事务ID,叫做transaction id(严格递增)
   (2)事务在启动时,找到已提交的最大事务ID记为up_limit_id。
   (3)事务在更新一条语句时,比如id=1改为了id=2.会把id=1和该行之前的row trx_id写到undo log里,
   并且在数据页上把id的值改为2,并且把修改这条语句的transaction id记在该行行头
   (4)再定一个规矩,一个事务要查看一条数据时,必须先用该事务的up_limit_id与该行的transaction id做比对,
   如果up_limit_id>=transaction id,那么可以看.如果up_limit_id<transaction id,则只能去undo log里去取。去undo log查找数据的时候,也需要做比对,必须up_limit_id>transaction id,才返回数据

4.什么是当前读,由于当前读都是先读后写,只能读当前的值,所以为当前读.会更新事务内的up_limit_id为该事务的transaction id

5.为什么rr能实现可重复读而rc不能,分两种情况
(1)快照读的情况下,rr不能更新事务内的up_limit_id,
而rc每次会把up_limit_id更新为快照读之前最新已提交事务的transaction id,则rc不能可重复读
(2)当前读的情况下,rr是利用record lock+gap lock来实现的,而rc没有gap,所以rc不能可重复读   

### 索引的选择

  对于查询过程来说：
a、普通索引，查到满足条件的第一个记录后，继续查找下一个记录，知道第一个不满足条件的记录
b、唯一索引，由于索引唯一性，查到第一个满足条件的记录后，停止检索
但是，两者的性能差距微乎其微。因为InnoDB根据数据页来读写的。
对于更新过程来说：
概念：change buffer
当需要更新一个数据页，如果数据页在内存中就直接更新，如果不在内存中，在不影响数据一致性的前提下，InnoDB会将这些更新操作缓存在change buffer中。下次查询需要访问这个数据页的时候，将数据页读入内存，然后执行change buffer中的与这个页有关的操作。

change buffer是可以持久化的数据。在内存中有拷贝，也会被写入到磁盘上

purge:将change buffer中的操作应用到原数据页上，得到最新结果的过程，成为purge
访问这个数据页会触发purge，系统有后台线程定期purge，在数据库正常关闭的过程中，也会执行purge

唯一索引的更新不能使用change buffer

change buffer用的是buffer pool里的内存，change buffer的大小，可以通过参数innodb_change_buffer_max_size来动态设置。这个参数设置为50的时候，表示change buffer的大小最多只能占用buffer pool的50%。

将数据从磁盘读入内存涉及随机IO的访问，是数据库里面成本最高的操作之一。 
change buffer 因为减少了随机磁盘访问，所以对更新性能的提升很明显。

change buffer使用场景
在一个数据页做purge之前，change buffer记录的变更越多，收益就越大。
对于写多读少的业务来说，页面在写完以后马上被访问到的概率比较小，此时change buffer的使用效果最好。这种业务模型常见的就是账单类、日志类的系统。

反过来，假设一个业务的更新模式是写入之后马上会做查询，那么即使满足了条件，将更新先记录在change buffer,但之后由于马上要访问这个数据页，会立即触发purge过程。
这样随机访问IO的次数不会减少，反而增加了change buffer的维护代价。所以，对于这种业务模式来说，change buffer反而起到了副作用。

索引的选择和实践：
如果业务代码已经保证不会写入重复数据，从性能角度出发尽可能使用普通索引。
redo log主要节省的是随机写磁盘的IO消耗(转成顺序写)，而change buffer主要节省的则是随机读磁盘的IO消耗。

#### 优化器存在选错索引的可能性，解决方案如下：

1.  **采用force index强行选择一个索引**

2. **我们可以考虑修改语句，引导MySQL使用我们期望的索引**

3. **在有些场景下，我们可以新建一个更合适的索引，来提供给优化器做选择，或删掉误用的索引。**

   

#### 字符串字段创建索引

1. 直接创建完整索引，这样可能比较占用空间；
2. 创建前缀索引，节省空间，但会增加查询扫描次数，并且不能使用覆盖索引；
3. 倒序存储，再创建前缀索引，用于绕过字符串本身前缀的区分度不够的问题；
4. 创建hash字段索引，查询性能稳定，有额外的存储和计算消耗，跟第三种方式一样，都不支持范围扫描。

#### order By 工作过程

**1. MySQL会为每个线程分配一个内存（sort_buffer）用于排序该内存大小为sort_buffer_size**

1. 如果排序的数据量小于sort_buffer_size，排序将会在内存中完成

2. 如果排序数据量很大，内存中无法存下这么多数据，则会使用磁盘临时文件来辅助排序，也称外部排序

3. 在使用外部排序时，MySQL会分成好几份单独的临时文件用来存放排序后的数据，然后在将这些文件合并成一个大文件

**2. mysql会通过遍历索引将满足条件的数据读取到sort_buffer，并且按照排序字段进行快速排序**

1. 如果查询的字段不包含在辅助索引中，需要按照辅助索引记录的主键返回聚集索引取出所需字段
2. 该方式会造成随机IO，在MySQL5.6提供了MRR的机制，会将辅助索引匹配记录的主键取出来在内存中进行排序，然后在回表
3. 按照情况建立联合索引来避免排序所带来的性能损耗，允许的情况下也可以建立覆盖索引来避免回表

**3. 全字段排序**

1. 通过索引将所需的字段全部读取到sort_buffer中
2. 按照排序字段进行排序
3. 将结果集返回给客户端

**缺点：**

1. 造成sort_buffer中存放不下很多数据，因为除了排序字段还存放其他字段，对sort_buffer的利用效率不高
2. 当所需排序数据量很大时，会有很多的临时文件，排序性能也会很差

**优点：**

MySQL认为内存足够大时会优先选择全字段排序，因为这种方式比rowid 排序避免了一次回表操作

**4. rowid排序**

1. 通过控制排序的行数据的长度来让sort_buffer中尽可能多的存放数据，max_length_for_sort_data
2. 只将需要排序的字段和主键读取到sort_buffer中，并按照排序字段进行排序
3. 按照排序后的顺序，取id进行回表取出想要获取的数据
4. 将结果集返回给客户端

优点：更好的利用内存的sort_buffer进行排序操作，尽量减少对磁盘的访问

缺点：回表的操作是随机IO，会造成大量的随机读，不一定就比全字段排序减少对磁盘的访问

#### 简述：如果有排序的sql优化的话，要在 查询的字段+where条件字段+ORDER字段加一个组合索引

原因是索引天然是有序的，

### sql语句逻辑相同，性能差异巨大的原因

1. 条件字段函数操作
     **对字段做了函数计算，就用不上索引了**

2. 隐式类型转换
    **varchar字段 参数int 优化器 会在varchar字段上转换函数，导致索引失效**

3. 隐式字符编码转换

    关联查询时两张表字符编码要一致，不然可能会转换

**索引字段不能进行函数操作，但是索引字段的参数可以函数操作 **

### join

#### join流程

1. 从驱动表中读入一行数据 R；
2. 从数据行R中，取出关联字段到表被驱动表里去查找；
3. 取出表被驱动表中满足条件的行，跟R组成一行，作为结果集的一部分；
4. 重复执行步骤1到3，直到驱动表的末尾循环结束。

#### 可不可以使用join

1. 如果可以使用被驱动表的索引，join语句还是有其优势的；
2. 不能使用被驱动表的索引，只能使用Block Nested-Loop Join算法，这样的语句就尽量不要使用；
3. 在使用join的时候，应该让小表做驱动表。

#### join优化

1. 给被驱动表的关联字段加上索引；
2. 基于临时表的改进方案，对于能够提前过滤出小数据的join语句来说，效果还是很好的；
3. MySQL目前的版本还不支持hash join，但你可以配合应用端自己模拟出来，理论上效果要好于临时表的方案。